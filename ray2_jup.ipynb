{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "#Def variables\n",
    "x = np.random.randn(100, 2)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "def train_bart(config):\n",
    "    # Modelo BART\n",
    "    with pm.Model() as bart_model:\n",
    "        # (Definición del modelo BART)\n",
    "\n",
    "        # Número de iteraciones de MCMC\n",
    "        num_samples = config.get(\"num_samples\", 1000)\n",
    "\n",
    "        # Muestreo MCMC\n",
    "        trace = pm.sample(num_samples)\n",
    "\n",
    "        # Guardar los resultados o métricas que quieras registrar, como el error de prueba, etc.\n",
    "\n",
    "        # Devolver la métrica que quieres maximizar o minimizar durante la búsqueda de hiperparámetros\n",
    "        return -np.mean(trace['y_obs'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Inicializar Ray (debes hacer esto antes de llamar a tune.run())\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    # Configuración de hiperparámetros a ajustar\n",
    "    config = {\n",
    "        \"num_samples\": tune.grid_search([1000, 2000, 3000]), # Puedes ajustar otros hiperparámetros también\n",
    "        # Agrega otros hiperparámetros para ajustar aquí...\n",
    "    }\n",
    "\n",
    "    # Lanzar la búsqueda de hiperparámetros en paralelo\n",
    "    result = tune.run(train_bart, config=config, num_samples=3, resources_per_trial={\"cpu\": 1})\n",
    "\n",
    "    # Obtener los mejores hiperparámetros encontrados y sus resultados\n",
    "    best_config = result.get_best_config(metric=\"neg_mean\")  # Metric to maximize/minimize\n",
    "    best_result = result.get_best_trial(metric=\"neg_mean\", mode=\"max\")  # Metric to maximize\n",
    "\n",
    "    print(\"Mejores hiperparámetros:\", best_config)\n",
    "    print(\"Mejor resultado:\", best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como imprimir los resultados en la consola para ver los hiperparámetros y las métricas de rendimiento de cada ejecución\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Lanzar la búsqueda de hiperparámetros en paralelo\n",
    "    result = tune.run(train_bart, config=config, num_samples=3, resources_per_trial={\"cpu\": 1})\n",
    "\n",
    "    # Obtener los mejores hiperparámetros encontrados y sus resultados\n",
    "    best_config = result.get_best_config(metric=\"neg_mean\")  # Metric to maximize/minimize\n",
    "    best_result = result.get_best_trial(metric=\"neg_mean\", mode=\"max\")  # Metric to maximize\n",
    "\n",
    "    # Imprimir todos los resultados\n",
    "    print(\"Resultados:\")\n",
    "    for trial in result.trials:\n",
    "        print(\"Hiperparámetros:\", trial.config)\n",
    "        print(\"Métrica de rendimiento:\", trial.last_result)\n",
    "        print(\"-----\")\n",
    "\n",
    "    print(\"Mejores hiperparámetros:\", best_config)\n",
    "    print(\"Mejor resultado:\", best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver los resultados de cada ejecución de Ray Tune\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Lanzar la búsqueda de hiperparámetros en paralelo\n",
    "    result = tune.run(train_bart, config=config, num_samples=3, resources_per_trial={\"cpu\": 1})\n",
    "\n",
    "    # Obtener los resultados en una lista\n",
    "    results_list = []\n",
    "    for trial in result.trials:\n",
    "        results_list.append((trial.config, trial.last_result))\n",
    "\n",
    "    # Imprimir todos los resultados\n",
    "    print(\"Resultados:\")\n",
    "    for config, result in results_list:\n",
    "        print(\"Hiperparámetros:\", config)\n",
    "        print(\"Métrica de rendimiento:\", result)\n",
    "        print(\"-----\")\n",
    "\n",
    "    # Obtener los mejores hiperparámetros encontrados y sus resultados\n",
    "    best_config = result.get_best_config(metric=\"neg_mean\")  # Metric to maximize/minimize\n",
    "    best_result = result.get_best_trial(metric=\"neg_mean\", mode=\"max\")  # Metric to maximize\n",
    "\n",
    "    print(\"Mejores hiperparámetros:\", best_config)\n",
    "    print(\"Mejor resultado:\", best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para visualizar resultados graficamente con Matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Lanzar la búsqueda de hiperparámetros en paralelo\n",
    "    result = tune.run(train_bart, config=config, num_samples=3, resources_per_trial={\"cpu\": 1})\n",
    "\n",
    "    # Obtener los resultados en una lista\n",
    "    results_list = []\n",
    "    for trial in result.trials:\n",
    "        results_list.append((trial.config, trial.last_result))\n",
    "\n",
    "    # Imprimir todos los resultados\n",
    "    print(\"Resultados:\")\n",
    "    for config, result in results_list:\n",
    "        print(\"Hiperparámetros:\", config)\n",
    "        print(\"Métrica de rendimiento:\", result)\n",
    "        print(\"-----\")\n",
    "\n",
    "    # Obtener los mejores hiperparámetros encontrados y sus resultados\n",
    "    best_config = result.get_best_config(metric=\"neg_mean\")  # Metric to maximize/minimize\n",
    "    best_result = result.get_best_trial(metric=\"neg_mean\", mode=\"max\")  # Metric to maximize\n",
    "\n",
    "    print(\"Mejores hiperparámetros:\", best_config)\n",
    "    print(\"Mejor resultado:\", best_result)\n",
    "\n",
    "    # Graficar la métrica de rendimiento en función de \"num_samples\"\n",
    "    num_samples_list = [config[\"num_samples\"] for config, _ in results_list]\n",
    "    metric_values = [-result[\"neg_mean\"] for _, result in results_list]  # Tomamos el negativo para maximizar\n",
    "\n",
    "    plt.plot(num_samples_list, metric_values, marker='o')\n",
    "    plt.xlabel(\"Número de muestras de MCMC\")\n",
    "    plt.ylabel(\"Error medio cuadrático negativo\")\n",
    "    plt.title(\"Evaluación del rendimiento en función de 'num_samples'\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
